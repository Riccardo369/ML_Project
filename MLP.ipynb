{"cells":[{"cell_type":"markdown","metadata":{"id":"Zfq39gHxGklX"},"source":["# **Library**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fHbju2NN-s_2"},"outputs":[],"source":["import random\n","import json\n","import numpy as np\n","from types import LambdaType\n","import matplotlib.pyplot as plt\n","import sympy as sp\n","import itertools as it"]},{"cell_type":"markdown","metadata":{"id":"pGLmMY5BkwdT"},"source":["# **Regularization**"]},{"cell_type":"markdown","metadata":{"id":"jnZsE1ZnRvob"},"source":["# **Simulator Class**"]},{"cell_type":"markdown","metadata":{"id":"ecHY-6H9RzRQ"},"source":["# Phase"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1SfbY3OR_Dz"},"outputs":[],"source":["class Phase:\n","  def __init__(self, Model, DataSet):\n","    self._Model = Model\n","    self._Dataset = DataSet\n","\n","    self._Metrics = dict()\n","\n","    self._Metrics[\"Loss\"] = []\n","    self._Metrics[\"Accuracy\"] = []\n","\n","  def GetMetrics(self):\n","    return self._Metrics\n","\n","  def Work(self):\n","    raise NotImplemented"]},{"cell_type":"markdown","metadata":{"id":"93nQCXxaTJ8h"},"source":["# Training Phase (Phase)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_auUw4BTQQL"},"outputs":[],"source":["class TrainPhase(Phase):\n","  def __init__(self, Model, TrainSet):\n","    super().__init__(Model, TrainSet)\n","\n","  def Work(self,BatchDimension,**Hyperparameters):\n","    if(BatchDimension < 1 or BatchDimension > len(self._Dataset)): raise ValueError(\"batch dimension must be above 0 and lower or equal to the dataset dimension\")\n","    Batches = BatchesExtraction(self._Dataset, BatchDimension)\n","\n","    TotalLossValue = 0\n","\n","    for Batch in Batches:\n","      #Do mean of all loss values\n","      LossValue = 0\n","      for r in Batch:\n","        InputVector=r[0]\n","        TargetValue=r[1]\n","        LossValue += self._Model.GetLossLambdaFunctionEvaluation()(self._Model.Predict(InputVector), TargetValue)\n","\n","      LossValue /= len(Batch)\n","\n","      #Add loss value batch to total loss value\n","      TotalLossValue += LossValue\n","\n","      #Calculate gradient\n","      #DirectionLoss = self._Model.GradientDirectionLoss(LossValue)\n","\n","      #Learn model\n","      self._Model.Learn(TotalLossValue)\n","\n","    #Apply mean of all loss values\n","    self._Metrics[\"Loss\"].append(TotalLossValue / len(Batches))"]},{"cell_type":"markdown","metadata":{"id":"ZhV80EJATbFE"},"source":["# Evaluation Phase (Phase)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXBi7UToTtMj"},"outputs":[],"source":["class EvaluationPhase(Phase):\n","  def __init__(self, Model, DataSet, n):\n","    super().__init__(Model, DataSet, n, lambda: True)\n","\n","  def Work(self):\n","\n","    Batches = BatchesExtraction(self._Dataset, 1)\n","\n","    TotalLossValue = 0\n","\n","    for Batch in Batches:\n","\n","      #Do mean of all loss values\n","      LossValue = 0\n","\n","      for r in Batch: LossValue += self._Model.GetLossLambdaFunctionEvaluation(self._Model.Predict(r[0]), r[1])\n","      LossValue /= len(r)\n","\n","      #Add loss value batch to total loss value\n","      TotalLossValue += LossValue\n","\n","    #Apply mean of all loss values\n","    self._Metrics[\"Loss\"].append(TotalLossValue / len(Batches))"]},{"cell_type":"markdown","metadata":{"id":"U2UVqbOLVVAz"},"source":["# Cross validation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tqBNXG4VbsJ"},"outputs":[],"source":["class CrossValidation:\n","  def __init__(self, Dataset, K):\n","    Data = random.sample(list(Dataset), len(Dataset))          #Shuffle data\n","    self.__Folds = np.split(Data, [len(Dataset)//K])           #Split data in k folds\n","    del Data                                                   #It is not necessary in memory anymore\n","\n","  def GetFoldsNum(self):\n","    return len(self.__Folds)\n","\n","  def GetKFold(self, K):\n","    ListFolds = list(self.__Folds)\n","    ValidationSet = np.array(ListFolds[K])\n","    del ListFolds[K]\n","    TrainingSet = np.concatenate(ListFolds)\n","    return np.array(TrainingSet, dtype=object), np.array(ValidationSet, dtype=object)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HnpYlUrq1xfD"},"outputs":[],"source":["Dataset = [[[11, 21, 31, 41], [51, 61]],\n","           [[12, 22, 32, 42], [52, 62]],\n","           [[13, 23, 33, 43], [53, 63]],\n","           [[14, 24, 34, 44], [54, 64]],\n","           [[15, 25, 35, 45], [55, 65]],\n","           [[16, 26, 36, 45], [56, 66]],\n","           [[17, 27, 37, 47], [57, 67]],\n","           [[18, 28, 38, 48], [58, 68]]]\n","\n","CV = CrossValidation(Dataset, 1)\n","\n","TR, VL = CV.GetKFold(0)\n","\n","print(TR)\n","print(\"\")\n","print(VL)"]},{"cell_type":"markdown","metadata":{"id":"UaNUlIL913Qt"},"source":["# Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9L6FeXfT_xpg"},"outputs":[],"source":["# test di training\n","\n","def update_weights(bridges_weights:list,last_output,loss):\n","  learning_rate= 0.1\n","  assert learning_rate > 0 and learning_rate < 1\n","  new_weights= map(bridges_weights)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QPj0YGFc7Z_B"},"source":["# ModelSelection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nI4WhJKl7dpx"},"outputs":[],"source":["#responsabilità: selezionare un modello, la classe è astratta e da essa poi dovranno ereditare altre classi che implemetano una strategia di validazione\n","class ModelSelection:\n","  def __init__(self,Model,TrSet,Retraining=False):\n","    self.__Model=Model\n","    self.__TrSet=TrSet\n","    self.__Retraining=Retraining\n","    # data una serie di iperparametri e un regola per selezionare i valori dalla epoch restituisce il risultato della selezione del modello\n","  def Select(self,EpochRule,Hyperparameters):\n","    raise NotImplemented\n"]},{"cell_type":"markdown","metadata":{"id":"eqmQWEeg8GN6"},"source":["# KFoldCV(ModelSelection)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmEKWSnvVLIr"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7Mx3AHD1Shiw"},"source":["# MAIN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wv6ZFXmjuBcn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7Qnv879dxUX"},"outputs":[],"source":["def weights_update_function(weigths,GradientLoss,LearningRate=0.1,WeightDecay=0):\n","  return list(map(lambda w: w +LearningRate*(GradientLoss + WeightDecay*w),weigths)) # nota : 0.1 = eta\n","\n","\n","def BuildTwoLevelFeedForward(InputSize,HiddenSize,OutputSize):\n","  LossFunction= lambda yo, yt: 1/2 * sum((yo - yt)**2)\n","  NN=NeuralNetwork(InputSize,OutputSize,LossFunction)\n","  InputLayer=NN.GetAllInputNeurons()\n","  OutputLayer=NN.GetAllOutputNeurons()\n","  HiddenLayer = [ ActivationNeuron(lambda x:x,weights_update_function,lambda x,y:0,LossFunction) for _ in range(HiddenSize) ]\n","  for InputNeuron in InputLayer:\n","    for HiddenNeuron in HiddenLayer:\n","      InputNeuron.AddConnectionTo(HiddenNeuron)\n","  for OutputNeuron in OutputLayer:\n","    for HiddenNeuron in HiddenLayer:\n","      HiddenNeuron.AddConnectionTo(OutputNeuron)\n","  NN.CalculateAllStructure()\n","  return NN\n","\n","TwoLevelFF=BuildTwoLevelFeedForward(10,5,3)\n","\n","DataSet=np.loadtxt('sample_data/california_housing_train.csv',delimiter=',',skiprows=1,dtype=np.float64)\n","\n","K=6\n","\n","# codice di esempio non ancroa funzionante\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-Mq2prILt-y"},"outputs":[],"source":["\n","training=TrainPhase(TwoLevelFF,Data[:100])\n","\n","for _ in range(100):\n","  training.Work()\n","  print(training.GetMetrics())\n","prova=dict()\n","prova[\"Training loss\"]=training.GetMetrics()[\"Loss\"]\n","\n","Graph(prova,[\"red\"],\"\",\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1702330483734,"user":{"displayName":"MIRKO MICHELE D'ANGELO","userId":"11344770875827290487"},"user_tz":-60},"id":"-TTm90OIyMBX","outputId":"b60590d3-52be-4010-a1d5-93dd1e6ae9a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["performing grid search on 4 hyperparamters with 100 combinations\n"]}],"source":["\n","\n","def ModelSelection(Model,DataSet,folds,*hyperparams):\n","  ModelSelectionPerformance=dict()\n","  TrainingPerformance=[]\n","  ValidationPerformance=[]\n","  cv=CrossValidation(DataSet,folds)\n","  for fold in range(cv.GetFoldsNum()):\n","    tr,vl = cv.GetKFold(fold)\n","    training=TrainPhase(Model,tr)\n","    for i in range(50):# fine training dopo un numero fisso di epoche / verrà cambiato con un criterio di fermata\n","      training.Work()\n","    evaluation=EvaluationPhase(Model,vl)\n","    evaluation.Work()\n","    TrainingPerformance.append(training.GetMetrics())\n","    ValidationPerformance.append(evaluation.GetMetrics())\n","  ModelSelectionPerformance[\"training\"]=TrainingPerformance\n","  ModelSelectionPerformance[\"validation\"]=ValidationPerformance\n","  ModelSelectionPerformance[\"hyperparameters\"]=dict()\n","  return ModelSelectionPerformance\n","\n","\n","\n","\n","\n","def DisplayKFoldPerformance(ModelSelectionData):\n","  if(len(ModelSelectionData[\"training\"])!=len(ModelSelectionData[\"training\"])): raise ValueError(\"folds metrics bust be of the same size\")\n","  XLen = max(max(map(len,ModelSelectionData[\"training\"])), max(map(len,ModelSelectionData[\"validation\"])))\n","  Xdata=np.linspace(0,XLen,XLen)\n","\n","\n","# hyperparameters\n","\n","LearningRate=np.linspace(0.1,0.9,10)\n","WeightDecay=np.linspace(0,2,10)# a.k.a. Lambda in Tikohonv regularization\n","FoldsNumber= [6]\n","BatchDimension= [10]\n","\n","ParameterGrid=list(it.product(LearningRate,WeightDecay,FoldsNumber,BatchDimension))\n","\n","print(f\"performing grid search on {len(ParameterGrid[0])} hyperparamters with {len(ParameterGrid)} combinations\")\n","\n","Model=TwoLevelFF\n","Data=Data\n","\n","\n","for hyperparameters in ParameterGrid:\n","  Results=ModelSelection(Model,Data,*hyperparameters)\n","\n","\n","\n"]}],"metadata":{"colab":{"collapsed_sections":["Zfq39gHxGklX","utHGxYqyUkPh","WJewTx3qYgg7","2kPeg3-hdKg8","_eVTuVrrGsyR","xhoRkef1YIjw","BNXWLglUlSyw","ZhV80EJATbFE","U2UVqbOLVVAz","UaNUlIL913Qt","QPj0YGFc7Z_B","eqmQWEeg8GN6"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
